"""import cv2
import face_recognition
import pyttsx3
import time

# Sesli motor baÅŸlat
engine = pyttsx3.init()
engine.setProperty('rate', 150)

def speak(text):
    print(f"[ğŸ”Š] {text}")
    engine.say(text)
    engine.runAndWait()

# 1. Referans fotoÄŸrafÄ± yÃ¼kle (aynÄ± klasÃ¶rde olmalÄ±)
reference_image_path = "E:\\opencv_udemy\\face_recognition\\images\\eje2.png"
reference_image = face_recognition.load_image_file(reference_image_path)
reference_encodings = face_recognition.face_encodings(reference_image)

if not reference_encodings:
    print("[ERROR] Referans fotoÄŸrafÄ±nda yÃ¼z bulunamadÄ±.")
    exit()

reference_encoding = reference_encodings[0]
print("[INFO] Referans fotoÄŸraf yÃ¼klendi.")

# 2. Kamera baÅŸlat
cap = cv2.VideoCapture(0)
time.sleep(2)

# 3. YÃ¼zÃ¼ merkezleyerek baÅŸlangÄ±Ã§ X koordinatÄ±nÄ± belirle
print("[INFO] YÃ¼z merkezi pozisyonu belirleniyor...")
reference_center_x = None
while True:
    ret, frame = cap.read()
    if not ret:
        continue
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    faces = face_recognition.face_locations(rgb)
    if faces:
        top, right, bottom, left = faces[0]
        reference_center_x = (left + right) // 2
        print(f"[INFO] YÃ¼z X referans merkezi: {reference_center_x}")
        speak("Face detected. Let's start.")
        break

# 4. Liveness komut sÄ±rasÄ±
expected_sequence = ['right', 'center', 'left']
movement_sequence = []
threshold = 50  # piksel farkÄ± toleransÄ±

for command in expected_sequence:
    speak(f"Please look {command}")
    print(f"[â¡ï¸] Komut bekleniyor: {command}")
    command_given_time = time.time()
    detected = False

    while time.time() - command_given_time < 7:
        ret, frame = cap.read()
        if not ret:
            continue
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        faces = face_recognition.face_locations(rgb)

        if faces:
            top, right, bottom, left = faces[0]
            current_center_x = (left + right) // 2

            movement = "center"
            if current_center_x < reference_center_x - threshold:
                movement = "right"  # ekranÄ±n sol tarafÄ± â†’ kullanÄ±cÄ±nÄ±n SAÄI
            elif current_center_x > reference_center_x + threshold:
                movement = "left"   # ekranÄ±n saÄŸ tarafÄ± â†’ kullanÄ±cÄ±nÄ±n SOLU

            cv2.putText(frame, f"Detected: {movement}", (30, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

            if movement == command:
                print(f"[âœ“] DoÄŸru hareket: {movement}")
                movement_sequence.append(movement)
                detected = True
                break

        cv2.imshow("Liveness Detection", frame)
        if cv2.waitKey(30) & 0xFF == ord('q'):
            break

        if detected:
            break

# 5. Liveness sonucu
if movement_sequence == expected_sequence:
    speak("Liveness check passed. Thank you.")
    print("[âœ…] CanlÄ±lÄ±k testi baÅŸarÄ±yla tamamlandÄ±.")

    # 6. YÃ¼z karÅŸÄ±laÅŸtÄ±rmasÄ± yap
    ret, final_frame = cap.read()
    if ret:
        cv2.imwrite("liveness_success.jpg", final_frame)
        print("[ğŸ“¸] Son kare kaydedildi.")

        final_rgb = cv2.cvtColor(final_frame, cv2.COLOR_BGR2RGB)
        live_encodings = face_recognition.face_encodings(final_rgb)

        if live_encodings:
            live_encoding = live_encodings[0]
            match_result = face_recognition.compare_faces([reference_encoding], live_encoding)[0]

            if match_result:
                print("[ğŸ‰] YÃ¼z eÅŸleÅŸti. Kimlik doÄŸrulandÄ±.")
                speak("Face match successful. Identity verified.")
            else:
                print("[âš ï¸] YÃ¼z eÅŸleÅŸmesi baÅŸarÄ±sÄ±z.")
                speak("Face does not match the reference image.")
        else:
            print("[âŒ] YÃ¼z tespit edilemedi.")
            speak("No face detected in the final frame.")
else:
    print("[âŒ] Liveness test failed.")
    speak("Liveness check failed.")

cap.release()
cv2.destroyAllWindows()
"""
import cv2
import face_recognition
import time
import pyttsx3

# Sesli konuÅŸma motoru baÅŸlat
engine = pyttsx3.init()
engine.setProperty('rate', 150)


def speak(text):
    print(f"[ğŸ”Š] {text}")
    try:
        engine.say(text)
        engine.runAndWait()
    except:
        pass  # bazÄ± sistemlerde kasma yapabiliyor, engelliyoruz


# Kamera baÅŸlat (dÃ¼ÅŸÃ¼k Ã§Ã¶zÃ¼nÃ¼rlÃ¼k)
cap = cv2.VideoCapture(0)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# Referans yÃ¼zÃ¼ yÃ¼kle
reference_image_path = "E:\\opencv_udemy\\face_recognition\\images\\enescan.jpg"
reference_image = face_recognition.load_image_file(reference_image_path)
reference_encodings = face_recognition.face_encodings(reference_image)
if not reference_encodings:
    print("[ERROR] Referans yÃ¼z bulunamadÄ±!")
    cap.release()
    exit()
reference_encoding = reference_encodings[0]
print("[INFO] Referans fotoÄŸraf yÃ¼klendi.")

# Liveness testi parametreleri
commands = ['right', 'center', 'left']
movements_done = []
face_center_x = None
required_movements = 3
frame_count = 0

# Ana dÃ¶ngÃ¼
print("[INFO] YÃ¼z merkezi pozisyonu belirleniyor...")
while True:
    ret, frame = cap.read()
    if not ret:
        break

    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    face_locations = face_recognition.face_locations(rgb)

    if face_locations:
        top, right, bottom, left = face_locations[0]
        face_center_x = (left + right) // 2
        print(f"[INFO] YÃ¼z X referans merkezi: {face_center_x}")
        speak("Face detected. Let's start.")
        break

cv2.waitKey(500)

# Hareketleri sÄ±rayla iste
for command in commands:
    speak(f"Please look {command}")
    print(f"[â¡ï¸] Komut bekleniyor: {command}")
    detected = False
    start_time = time.time()

    while time.time() - start_time < 7:
        ret, frame = cap.read()
        if not ret:
            break

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        if frame_count % 3 == 0:  # sadece her 3 karede bir iÅŸlem yap
            face_locations = face_recognition.face_locations(rgb)

            if face_locations:
                top, right, bottom, left = face_locations[0]
                current_x = (left + right) // 2

                if face_center_x:
                    movement = None
                    if current_x < face_center_x - 40:
                        movement = 'right'  # kullanÄ±cÄ±nÄ±n SAÄI â†’ ekranÄ±n SOLU
                    elif current_x > face_center_x + 40:
                        movement = 'left'  # kullanÄ±cÄ±nÄ±n SOLU â†’ ekranÄ±n SAÄI
                    else:
                        movement = 'center'

                    cv2.putText(frame, f"Detected: {movement}", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

                    if movement == command:
                        print(f"[âœ“] DoÄŸru hareket: {movement}")
                        movements_done.append(movement)
                        detected = True
                        break

        if frame_count % 2 == 0:
            cv2.imshow("Liveness Detection", frame)
        frame_count += 1

        if cv2.waitKey(10) & 0xFF == ord('q'):
            break

    if not detected:
        print(f"[!] {command} hareketi algÄ±lanamadÄ±.")

# CanlÄ±lÄ±k testi tamamlandÄ±ysa devam et
if len(movements_done) == required_movements:
    speak("Liveness check passed. Thank you.")
    print("[âœ…] CanlÄ±lÄ±k testi baÅŸarÄ±yla tamamlandÄ±.")

    # Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ al
    ret, final_frame = cap.read()
    if ret:
        cv2.imwrite("liveness_success.jpg", final_frame)
        print("[ğŸ“¸] Son kare kaydedildi.")

        # KarÅŸÄ±laÅŸtÄ±rma
        live_encodings = face_recognition.face_encodings(final_frame)
        if live_encodings:
            match_result = face_recognition.compare_faces([reference_encoding], live_encodings[0])[0]
            if match_result:
                print("[ğŸ‰] YÃ¼z eÅŸleÅŸti. Kimlik doÄŸrulandÄ±.")
                speak("Face match successful. Identity verified.")
            else:
                print("[âŒ] YÃ¼z eÅŸleÅŸmedi. Kimlik doÄŸrulanamadÄ±.")
                speak("Face does not match. Identity not verified.")
        else:
            print("[âš ï¸] CanlÄ± yÃ¼z algÄ±lanamadÄ±.")
else:
    print("[âŒ] CanlÄ±lÄ±k testi baÅŸarÄ±sÄ±z.")

cap.release()
cv2.destroyAllWindows()

